{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15ee7d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda_envs\\nlp_project\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78da743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Muat Model dan Tokenizer yang Telah Disimpan ---\n",
    "MODEL_DIR = './model_final'\n",
    "\n",
    "try:\n",
    "    # Muat tokenizer dan model dari direktori yang sama\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n",
    "except EnvironmentError:\n",
    "    print(f\"Direktori model '{MODEL_DIR}' tidak ditemukan. Pastikan Anda sudah menjalankan langkah penyimpanan sebelumnya.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aad7124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model berhasil dimuat dan berjalan di device: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Siapkan Device (GPU/CPU) ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"Model berhasil dimuat dan berjalan di device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e762475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Buat Fungsi untuk Prediksi ---\n",
    "def predict(text):\n",
    "    \"\"\"Fungsi untuk memprediksi label dari sebuah teks.\"\"\"\n",
    "    # Set model ke mode evaluasi\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenisasi teks input\n",
    "    encoding = tokenizer.encode_plus(\n",
    "      text,\n",
    "      add_special_tokens=True,   # Menambahkan simbol khusus di awal dan akhir kalimat agar model bisa memahami strukturnya\n",
    "      max_length=128, # Membatasi panjang kalimat agar maksimal 128 kata (token)        \n",
    "      padding='max_length', # Jika kalimatnya terlalu pendek, akan ditambah kata kosong agar panjangnya sama\n",
    "      truncation=True, # Jika kalimatnya terlalu panjang, sisanya akan dibuang agar tidak melebihi batas\n",
    "      return_attention_mask=True,  # Memberi tanda pada bagian mana yang merupakan kalimat asli dan mana yang hanya tambahan\n",
    "      return_tensors='pt',  # Mengubah hasil pemrosesan menjadi format khusus yang bisa dibaca oleh mesin (PyTorch)\n",
    "    )\n",
    "\n",
    "    # Pindahkan tensor ke device\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    # Lakukan prediksi tanpa menghitung gradien\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        # Ambil prediksi dengan probabilitas tertinggi\n",
    "        prediction_idx = torch.argmax(outputs.logits, dim=1).item()\n",
    "\n",
    "    # Mapping indeks ke label yang bisa dibaca manusia\n",
    "    label_map = {0: 'Bukan Ujaran Kebencian', 1: 'Ujaran Kebencian'}\n",
    "    \n",
    "    return label_map[prediction_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadf717c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tes Model Klasifikasi Ujaran Kebencian ---\n",
      "Ketik 'exit' untuk keluar.\n",
      "Teks: jokowi buruk rupa\n",
      "Prediksi: Ujaran Kebencian\n",
      "Teks: jokowi jomok\n",
      "Prediksi: Bukan Ujaran Kebencian\n",
      "Teks: madara ganteng dan melihara anjing\n",
      "Prediksi: Bukan Ujaran Kebencian\n",
      "Teks: madara anjing\n",
      "Prediksi: Ujaran Kebencian\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Buat Loop Interaktif ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"\\n--- Tes Model Klasifikasi Ujaran Kebencian ---\")\n",
    "    print(\"Ketik 'exit' untuk keluar.\")\n",
    "    \n",
    "    while True:\n",
    "        # Minta input dari pengguna\n",
    "        user_input = input(\"\\nMasukkan teks: \")\n",
    "\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Terima kasih! Program berhenti.\")\n",
    "            break\n",
    "        \n",
    "        # Lakukan prediksi dan cetak hasilnya bersama teks input\n",
    "        prediction_result = predict(user_input)\n",
    "        print(f\"Teks: {user_input}\")\n",
    "        print(f\"Prediksi: {prediction_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cab91f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lime\n",
      "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: matplotlib in d:\\conda_envs\\nlp_project\\lib\\site-packages (from lime) (3.9.4)\n",
      "Requirement already satisfied: numpy in d:\\conda_envs\\nlp_project\\lib\\site-packages (from lime) (1.26.4)\n",
      "Requirement already satisfied: scipy in d:\\conda_envs\\nlp_project\\lib\\site-packages (from lime) (1.13.1)\n",
      "Requirement already satisfied: tqdm in d:\\conda_envs\\nlp_project\\lib\\site-packages (from lime) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in d:\\conda_envs\\nlp_project\\lib\\site-packages (from lime) (1.6.1)\n",
      "Collecting scikit-image>=0.12 (from lime)\n",
      "  Downloading scikit_image-0.24.0-cp39-cp39-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: networkx>=2.8 in d:\\conda_envs\\nlp_project\\lib\\site-packages (from scikit-image>=0.12->lime) (3.2.1)\n",
      "Requirement already satisfied: pillow>=9.1 in d:\\conda_envs\\nlp_project\\lib\\site-packages (from scikit-image>=0.12->lime) (11.3.0)\n",
      "Collecting imageio>=2.33 (from scikit-image>=0.12->lime)\n",
      "  Downloading imageio-2.37.2-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image>=0.12->lime)\n",
      "  Downloading tifffile-2024.8.30-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: packaging>=21 in d:\\conda_envs\\nlp_project\\lib\\site-packages (from scikit-image>=0.12->lime) (25.0)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image>=0.12->lime)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\conda_envs\\nlp_project\\lib\\site-packages (from scikit-learn>=0.18->lime) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\conda_envs\\nlp_project\\lib\\site-packages (from scikit-learn>=0.18->lime) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\conda_envs\\nlp_project\\lib\\site-packages (from matplotlib->lime) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\conda_envs\\nlp_project\\lib\\site-packages (from matplotlib->lime) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\conda_envs\\nlp_project\\lib\\site-packages (from matplotlib->lime) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\conda_envs\\nlp_project\\lib\\site-packages (from matplotlib->lime) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\conda_envs\\nlp_project\\lib\\site-packages (from matplotlib->lime) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\conda_envs\\nlp_project\\lib\\site-packages (from matplotlib->lime) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in d:\\conda_envs\\nlp_project\\lib\\site-packages (from matplotlib->lime) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in d:\\conda_envs\\nlp_project\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->lime) (3.23.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\conda_envs\\nlp_project\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
      "Requirement already satisfied: colorama in d:\\conda_envs\\nlp_project\\lib\\site-packages (from tqdm->lime) (0.4.6)\n",
      "Downloading scikit_image-0.24.0-cp39-cp39-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.9 MB 3.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.6/12.9 MB 4.0 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.6/12.9 MB 4.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.4/12.9 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.5/12.9 MB 4.2 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 6.0/12.9 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.1/12.9 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.9/12.9 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.7/12.9 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 9.4/12.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.2/12.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.1/12.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 4.2 MB/s  0:00:03\n",
      "Downloading imageio-2.37.2-py3-none-any.whl (317 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading tifffile-2024.8.30-py3-none-any.whl (227 kB)\n",
      "Building wheels for collected packages: lime\n",
      "  Building wheel for lime (setup.py): started\n",
      "  Building wheel for lime (setup.py): finished with status 'done'\n",
      "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283918 sha256=5cda28a61e51aaa6484b3a605d746babf3f68c9b93056a38157fdd514e4fe2e5\n",
      "  Stored in directory: d:\\pip_cache\\wheels\\ed\\d7\\c9\\5a0130d06d6310bc6cbe55220e6e72dcb8c4eff9a478717066\n",
      "Successfully built lime\n",
      "Installing collected packages: tifffile, lazy-loader, imageio, scikit-image, lime\n",
      "\n",
      "   ---------------------------------------- 0/5 [tifffile]\n",
      "   ---------------------------------------- 0/5 [tifffile]\n",
      "   ---------------------------------------- 0/5 [tifffile]\n",
      "   ---------------------------------------- 0/5 [tifffile]\n",
      "   ---------------------------------------- 0/5 [tifffile]\n",
      "   ---------------- ----------------------- 2/5 [imageio]\n",
      "   ---------------- ----------------------- 2/5 [imageio]\n",
      "   ---------------- ----------------------- 2/5 [imageio]\n",
      "   ---------------- ----------------------- 2/5 [imageio]\n",
      "   ---------------- ----------------------- 2/5 [imageio]\n",
      "   ---------------- ----------------------- 2/5 [imageio]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   ------------------------ --------------- 3/5 [scikit-image]\n",
      "   -------------------------------- ------- 4/5 [lime]\n",
      "   ---------------------------------------- 5/5 [lime]\n",
      "\n",
      "Successfully installed imageio-2.37.2 lazy-loader-0.4 lime-0.2.0.1 scikit-image-0.24.0 tifffile-2024.8.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'lime' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'lime'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "!pip install lime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34f250c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda_envs\\nlp_project\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model berhasil dimuat dan berjalan di device: cuda\n",
      "\n",
      "--- Tes Model Klasifikasi Ujaran Kebencian + Deteksi Kata Pemicu ---\n",
      "Ketik 'exit' untuk keluar.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üß† MODEL INDOBERT + CETAK KATA YANG MEMICU (LIME EXPLANATION)\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "\n",
    "# Coba impor LIME, kalau belum ada langsung install\n",
    "try:\n",
    "    from lime.lime_text import LimeTextExplainer\n",
    "except ImportError:\n",
    "    import os\n",
    "    os.system('pip install -q lime')\n",
    "    from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# --- 1. Muat Model dan Tokenizer ---\n",
    "MODEL_DIR = './model_final'\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n",
    "except EnvironmentError:\n",
    "    print(f\"Direktori model '{MODEL_DIR}' tidak ditemukan. Pastikan sudah disimpan sebelumnya.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Siapkan Device (GPU/CPU) ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"Model berhasil dimuat dan berjalan di device: {device}\")\n",
    "\n",
    "# --- 3. Fungsi Prediksi Probabilitas (untuk LIME) ---\n",
    "def predict_proba(texts):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    for text in texts:\n",
    "        encoding = tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=128,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoding)\n",
    "            probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "            all_probs.append(probs.cpu().numpy().flatten())\n",
    "    return np.array(all_probs)\n",
    "\n",
    "# --- 4. Fungsi Prediksi Label ---\n",
    "def predict_label(text):\n",
    "    probs = predict_proba([text])[0]\n",
    "    label_idx = np.argmax(probs)\n",
    "    label_map = {0: 'Bukan Ujaran Kebencian', 1: 'Ujaran Kebencian'}\n",
    "    return label_map[label_idx], probs\n",
    "\n",
    "# --- 5. Fungsi Interpretasi dan Ekstraksi Kata Kasar ---\n",
    "def get_trigger_words(text, threshold=0.05):\n",
    "    \"\"\"Menemukan kata yang paling memicu model mendeteksi ujaran kebencian\"\"\"\n",
    "    explainer = LimeTextExplainer(class_names=['Non Hate', 'Hate'])\n",
    "    exp = explainer.explain_instance(text, predict_proba, num_features=10)\n",
    "    \n",
    "    # Ambil kata yang bobotnya positif (kontribusi ke kelas Hate)\n",
    "    trigger_words = [word for word, weight in exp.as_list() if weight > threshold]\n",
    "    return trigger_words, exp\n",
    "\n",
    "# --- 6. Loop Interaktif ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"\\n--- Tes Model Klasifikasi Ujaran Kebencian + Deteksi Kata Pemicu ---\")\n",
    "    print(\"Ketik 'exit' untuk keluar.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"Masukkan teks: \").strip()\n",
    "\n",
    "        # Jika kosong\n",
    "        if not user_input:\n",
    "            print(\"‚ö†Ô∏è  Harap masukkan teks terlebih dahulu.\\n\")\n",
    "            continue\n",
    "\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Terima kasih! Program dihentikan.\")\n",
    "            break\n",
    "\n",
    "        label, probs = predict_label(user_input)\n",
    "        print(f\"\\nTeks: {user_input}\")\n",
    "        print(f\"Prediksi: {label}\")\n",
    "        print(f\"Probabilitas [Non Hate, Hate]: {np.round(probs, 3)}\")\n",
    "\n",
    "        # Dapatkan kata-kata pemicu\n",
    "        trigger_words, exp = get_trigger_words(user_input)\n",
    "\n",
    "        if trigger_words:\n",
    "            print(f\"Kata yang memicu deteksi hate speech: {trigger_words}\")\n",
    "        else:\n",
    "            print(\"Tidak ditemukan kata pemicu hate speech yang signifikan.\")\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
